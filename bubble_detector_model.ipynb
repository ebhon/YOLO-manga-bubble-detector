{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436c0246",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image, ImageFile\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from collections import Counter\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # allow truncated image loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09606d0",
   "metadata": {},
   "source": [
    "### 1.Organize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset splitter for YOLO‑style images/labels.\n",
    "\n",
    "Reads raw JPEG/PNG images plus corresponding YOLO‑format `.txt` label files\n",
    "from `Dataset/raw_images` and `Dataset/raw_labels`, performs a stratified\n",
    "80 / 20 split (per class) into *train* and *val* subsets, and copies the\n",
    "results to:\n",
    "\n",
    "    Dataset/images/train/   *.jpg / *.png\n",
    "    Dataset/labels/train/   *.txt\n",
    "    Dataset/images/val/\n",
    "    Dataset/labels/val/\n",
    "\n",
    "The split preserves class balance as far as possible by allocating images\n",
    "class‑wise before shuffling. A summary of the original class distribution\n",
    "and final split sizes is printed.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 0. Define source / target directories\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "base_dir = \"Dataset\"\n",
    "raw_images_dir = os.path.join(base_dir, \"raw_images\")    # source images\n",
    "raw_labels_dir = os.path.join(base_dir, \"raw_labels\")    # source YOLO labels\n",
    "\n",
    "images_dir = os.path.join(base_dir, \"images\")            # destination images\n",
    "labels_dir = os.path.join(base_dir, \"labels\")            # destination labels\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 1. Create train/val sub‑folders (if they do not already exist)\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "for split in (\"train\", \"val\"):\n",
    "    os.makedirs(os.path.join(images_dir, split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(labels_dir, split), exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 2. Collect list of all image filenames\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "image_files = [\n",
    "    f\n",
    "    for f in os.listdir(raw_images_dir)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 3. Utility: count class occurrences in a single YOLO label file\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "def count_classes_in_label_file(label_path: str) -> Counter:\n",
    "    \"\"\"\n",
    "    Count how many instances of each class index appear in a YOLO label file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label_path : str\n",
    "        Path to a `.txt` file whose lines follow the YOLO format:\n",
    "        ``<class_id> x_center y_center width height``\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    collections.Counter\n",
    "        Mapping ``class_id -> instance_count``.\n",
    "    \"\"\"\n",
    "    class_counts: Counter[int] = Counter()\n",
    "    try:\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:          # valid YOLO row\n",
    "                    class_id = int(parts[0])\n",
    "                    class_counts[class_id] += 1\n",
    "    except Exception as e:                  # file missing / unreadable\n",
    "        print(f\"Error reading {label_path}: {e}\")\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 4. Compute overall class distribution in the raw dataset\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "total_class_counts: Counter[int] = Counter()\n",
    "for img_file in image_files:\n",
    "    name, _ = os.path.splitext(img_file)\n",
    "    label_path = os.path.join(raw_labels_dir, name + \".txt\")\n",
    "    if os.path.exists(label_path):\n",
    "        total_class_counts.update(count_classes_in_label_file(label_path))\n",
    "\n",
    "print(\"Class Distribution in original dataset:\")\n",
    "for cid, cnt in sorted(total_class_counts.items()):\n",
    "    print(f\"  Class {cid}: {cnt} instances\")\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 5. Group image filenames by the classes they contain\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "class_to_images: dict[int, list[str]] = {cid: [] for cid in total_class_counts}\n",
    "for img_file in image_files:\n",
    "    name, _ = os.path.splitext(img_file)\n",
    "    lbl_path = os.path.join(raw_labels_dir, name + \".txt\")\n",
    "    if os.path.exists(lbl_path):\n",
    "        for cid in count_classes_in_label_file(lbl_path):\n",
    "            class_to_images[cid].append(img_file)\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 6. Stratified 80/20 split per class\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "random.seed(42)                                 # reproducibility\n",
    "train_files: set[str] = set()\n",
    "val_files: set[str] = set()\n",
    "\n",
    "for cid, imgs in class_to_images.items():\n",
    "    random.shuffle(imgs)\n",
    "    split_idx = int(len(imgs) * 0.8)\n",
    "    train_files.update(imgs[:split_idx])        # 80 % to train\n",
    "    val_files.update(imgs[split_idx:])          # 20 % to val\n",
    "\n",
    "# ensure an image is not in both sets\n",
    "val_files = list(val_files - train_files)\n",
    "train_files = list(train_files)\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 7. File‑copy helper\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "def move_files(file_list: list[str], img_dst: str, lbl_dst: str) -> None:\n",
    "    \"\"\"\n",
    "    Copy images and their YOLO label files to destination folders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_list : list[str]\n",
    "        Filenames (with extension) to move.\n",
    "    img_dst : str\n",
    "        Directory to receive images.\n",
    "    lbl_dst : str\n",
    "        Directory to receive label `.txt` files.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * The function uses ``shutil.copy`` so the originals remain untouched.\n",
    "    * An image is copied only if both image and label exist.\n",
    "    \"\"\"\n",
    "    for file in file_list:\n",
    "        name, _ = os.path.splitext(file)\n",
    "        img_src = os.path.join(raw_images_dir, file)\n",
    "        lbl_src = os.path.join(raw_labels_dir, name + \".txt\")\n",
    "\n",
    "        if os.path.exists(img_src) and os.path.exists(lbl_src):\n",
    "            shutil.copy(img_src, os.path.join(img_dst, file))\n",
    "            shutil.copy(lbl_src, os.path.join(lbl_dst, name + \".txt\"))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 8. Copy train and val splits\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "move_files(train_files, os.path.join(images_dir, \"train\"), os.path.join(labels_dir, \"train\"))\n",
    "move_files(val_files,   os.path.join(images_dir, \"val\"),   os.path.join(labels_dir, \"val\"))\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 9. Report final stats\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "print(f\"Total images: {len(image_files)}\")\n",
    "print(f\"Train images: {len(train_files)}\")\n",
    "print(f\"Val images:   {len(val_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f7c32",
   "metadata": {},
   "source": [
    "### 2. Fix truncated Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04021878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_and_save_images(folder_path: str) -> int:\n",
    "    \"\"\"\n",
    "    Re‑encode every image inside *folder_path* to RGB and overwrite it in place.\n",
    "\n",
    "    Purpose\n",
    "    -------\n",
    "    Some images in scraped or legacy datasets are partially corrupted or stored\n",
    "    in colour spaces (CMYK, indexed, etc.) that can confuse training code.\n",
    "    Re‑opening and re‑saving with Pillow forces a clean RGB decode/encode pass,\n",
    "    fixing many such issues.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Directory that holds the images to repair.  \n",
    "        Only filenames ending with ``.jpg``, ``.jpeg`` or ``.png`` (case‑insensitive)\n",
    "        are processed; all others are ignored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Count of images successfully rewritten.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * The original files are **overwritten**; make a backup first if needed.  \n",
    "    * Any file Pillow cannot open is skipped with a console warning.  \n",
    "    * Use this on your train/val image folders before YOLO training to avoid\n",
    "      mysterious “broken data” errors.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> n_fixed = reload_and_save_images(\"Dataset/images/train\")\n",
    "    >>> print(f\"{n_fixed} images repaired.\")\n",
    "    \"\"\"\n",
    "    fixed_count = 0\n",
    "\n",
    "    # iterate over everything in the directory\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # process only recognised image extensions\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "\n",
    "            try:\n",
    "                img = Image.open(path)          # ⇢ decode file\n",
    "                img = img.convert(\"RGB\")        # ⇢ force RGB colour space\n",
    "                img.save(path, optimize=True)   # ⇢ re‑encode & overwrite\n",
    "                fixed_count += 1                # ⇢ track successes\n",
    "            except Exception as e:\n",
    "                # log but continue on any unreadable/corrupted file\n",
    "                print(f\"Skipping {filename}: {e}\")\n",
    "\n",
    "    return fixed_count\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# Run the repair pass on both training and validation image folders\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "print(\n",
    "    f\"Fixed {reload_and_save_images(os.path.join(images_dir, 'train'))} training images\"\n",
    ")\n",
    "print(\n",
    "    f\"Fixed {reload_and_save_images(os.path.join(images_dir, 'val'))} validation images\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb6a25",
   "metadata": {},
   "source": [
    "### 3. Create data.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb540eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute inverse‑frequency class weights and build a YOLO data YAML that\n",
    "includes those weights for imbalance‑aware training.\n",
    "\n",
    "Given `total_class_counts` (a Counter produced earlier), we:\n",
    "1. Calculate an inverse‑frequency weight for each class\n",
    "2. Normalise so the largest weight equals 1.0\n",
    "3. Print the weights for inspection\n",
    "4. Assemble a `data_balanced.yaml` file pointing to train/val folders and\n",
    "   embedding the weight list.\n",
    "\n",
    "The resulting YAML can be passed to Ultralytics YOLOv8:\n",
    "\n",
    "    yolo detect train data=data_balanced.yaml model=yolov8n.pt ...\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 1. Compute inverse‑frequency weights\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "total_instances = sum(total_class_counts.values())  # total labelled objects\n",
    "class_weights: dict[int, float] = {}\n",
    "\n",
    "for class_id, count in total_class_counts.items():\n",
    "    # weight ∝ 1 / frequency  (= N_total / (K * n_i))\n",
    "    class_weights[class_id] = total_instances / (len(total_class_counts) * count)\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 2. Normalise so the largest weight is 1.0 (keeps values in a nicer range)\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "max_weight = max(class_weights.values())\n",
    "class_weights = {cid: w / max_weight for cid, w in class_weights.items()}\n",
    "\n",
    "print(\"Class weights for training:\")\n",
    "for cid, wt in class_weights.items():\n",
    "    print(f\"  Class {cid}: {wt:.2f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 3. Create list in class‑index order to drop into YAML\n",
    "#    (missing classes default to weight 1.0)\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "weight_list = [\n",
    "    class_weights.get(i, 1.0) for i in range(max(class_weights.keys()) + 1)\n",
    "]\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 4. Assemble the YOLO data YAML with the computed weights\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "data_yaml = f\"\"\"\n",
    "path: {os.path.abspath(base_dir)}        # dataset root\n",
    "train: images/train                      # relative to `path`\n",
    "val: images/val\n",
    "\n",
    "names:                                   # class index → label\n",
    "    0: bubble\n",
    "    1: narration\n",
    "    2: other\n",
    "    3: text\n",
    "    4: ui\n",
    "\n",
    "# Automatically generated class weights\n",
    "class_weights: {weight_list}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data_balanced.yaml\", \"w\") as f:\n",
    "    f.write(data_yaml)\n",
    "\n",
    "print(\"Wrote data_balanced.yaml with class weights.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a940cfd",
   "metadata": {},
   "source": [
    "### 4. Train YOLOV8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a YOLOv8 model on the balanced manga‑bubble dataset, print core\n",
    "validation metrics, and define a heuristic post‑processing helper.\n",
    "\"\"\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# Start from the tiny YOLOv8‑N weights to avoid bias from previous finetunes\n",
    "# --------------------------------------------------------------------------- #\n",
    "model = YOLO('yolov8n.pt')  # Start fresh to reduce historical bias\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# Launch training with data‑augmentation and early‑stopping params\n",
    "# --------------------------------------------------------------------------- #\n",
    "results = model.train(\n",
    "    data=\"data_balanced.yaml\",  # YAML built earlier with class weights/paths\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    patience=15,   # stop if val metric stalls for 15 epochs\n",
    "    batch=16,\n",
    "    cos_lr=True,   # cosine learning‑rate schedule\n",
    "    mixup=0.1,     # mixup augmentation probability\n",
    "    copy_paste=0.1,  # copy‑paste augmentation probability\n",
    "    degrees=10.0,  # random rotation ±10°\n",
    "    scale=0.5,     # random scaling (0.5–1.5)\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# Print best metrics stored inside the Ultralytics Results object\n",
    "# --------------------------------------------------------------------------- #\n",
    "metrics = results.results_dict\n",
    "print(\"Training Complete\")\n",
    "\n",
    "try:\n",
    "    # Keys differ slightly across package versions, so we use .get() fallbacks\n",
    "    print(f\"Best mAP@0.5:      {metrics.get('metrics/mAP50(B)',  metrics.get('mAP50',      0)):.4f}\")\n",
    "    print(f\"Best mAP@0.5:95:   {metrics.get('metrics/mAP50-95(B)', metrics.get('mAP50-95', 0)):.4f}\")\n",
    "    print(f\"Best Precision:    {metrics.get('metrics/precision(B)', metrics.get('precision', 0)):.4f}\")\n",
    "    print(f\"Best Recall:       {metrics.get('metrics/recall(B)',    metrics.get('recall',    0)):.4f}\")\n",
    "except Exception:\n",
    "    print(\"Could not access metrics directly. Check the results object for details.\")\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# Post‑processing: simple heuristics to fix common mis‑classifications\n",
    "# --------------------------------------------------------------------------- #\n",
    "def apply_post_processing_rules(results):\n",
    "    \"\"\"\n",
    "    Apply rule‑based tweaks to raw YOLO detections for manga bubble layouts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : list[ultralytics.engine.results.Results]\n",
    "        Output from ``model(image_path)``.  \n",
    "        Each item exposes ``xyxy[0]`` (tensor, shape *N×6*):\n",
    "        ``x1,y1,x2,y2,conf,cls``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict]\n",
    "        Cleaned detections—one dict per box with keys:\n",
    "        ``x, y, width, height, confidence, class``.\n",
    "\n",
    "    Rules implemented\n",
    "    -----------------\n",
    "    1. **Narration squares** – if a box is nearly square (aspect 0.9‑1.1),\n",
    "       predicted as class 0 with conf < 0.9 → re‑label to class 1.\n",
    "    2. **Wide UI strips** – if width/height > 3, not already class 3, conf < 0.85\n",
    "       → re‑label to class 3.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * The original `results` object is **not** modified.\n",
    "    * Thresholds were picked empirically—tune for other domains if needed.\n",
    "    \"\"\"\n",
    "    processed_results = []\n",
    "\n",
    "    for result in results:              # iterate over batch (often 1 image)\n",
    "        for box in result.xyxy[0]:      # each row: x1,y1,x2,y2,conf,cls\n",
    "            x1, y1, x2, y2, conf, cls = box.tolist()\n",
    "\n",
    "            width  = x2 - x1\n",
    "            height = y2 - y1\n",
    "            aspect_ratio = width / height if height else 0\n",
    "\n",
    "            # Rule 1: almost‑square speech bubble → narration\n",
    "            if 0.9 < aspect_ratio < 1.1 and cls == 0 and conf < 0.9:\n",
    "                cls = 1\n",
    "\n",
    "            # Rule 2: extra‑wide rectangle → UI element\n",
    "            if width / height > 3.0 and cls != 3 and conf < 0.85:\n",
    "                cls = 3\n",
    "\n",
    "            processed_results.append({\n",
    "                'x': x1,\n",
    "                'y': y1,\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'confidence': conf,\n",
    "                'class': cls\n",
    "            })\n",
    "\n",
    "    return processed_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862d660",
   "metadata": {},
   "source": [
    "### Prediction test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71b424",
   "metadata": {},
   "source": [
    "| using best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197bc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inference pipeline:\n",
    "\n",
    "1. Load the best fine‑tuned weights.\n",
    "2. Ensure a *test_set* folder exists (create and pre‑fill with a few val images\n",
    "   if necessary).\n",
    "3. Re‑save test images to catch hidden corruptions.\n",
    "4. Run YOLOv8 inference, then apply heuristic post‑processing.\n",
    "5. Save visualised predictions to disk.\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 1. Load the trained checkpoint\n",
    "# --------------------------------------------------------------------------- #\n",
    "best_model = YOLO(\"runs/detect/train12/weights/best.pt\")   # path to best.pt\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 2. Prepare a small test directory\n",
    "# --------------------------------------------------------------------------- #\n",
    "test_dir = os.path.join(base_dir, \"test_set\")\n",
    "\n",
    "if not os.path.exists(test_dir):\n",
    "    print(f\"Warning: Test directory {test_dir} does not exist. Creating it.\")\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # If completely empty, copy up to 5 validation images for a quick demo\n",
    "    for i, file in enumerate(val_files[:5]):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        shutil.copy(os.path.join(raw_images_dir, file), test_dir)\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 3. Sanitise test images (repair colour mode / corruption)\n",
    "# --------------------------------------------------------------------------- #\n",
    "reload_and_save_images(test_dir)\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 4. Run inference and apply rule‑based clean‑up\n",
    "# --------------------------------------------------------------------------- #\n",
    "results = best_model.predict(test_dir, save=True)  # Ultralytics will create a\n",
    "                                                   # runs/predict folder\n",
    "\n",
    "processed_results = apply_post_processing_rules(results)\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 5. Save the processed detections as visualisations\n",
    "# --------------------------------------------------------------------------- #\n",
    "for i, result in enumerate(processed_results):\n",
    "    # result.save() draws boxes on the original image; we give each a new name\n",
    "    result.save(filename=f\"processed_{i}.jpg\")\n",
    "\n",
    "print(\"Inference complete with post-processing rules applied\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
